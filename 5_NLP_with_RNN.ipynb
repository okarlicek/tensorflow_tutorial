{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbba8c0",
   "metadata": {},
   "source": [
    "## Encoding Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa287da3",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc89d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2, 2: 3, 3: 3, 4: 3, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n",
      "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
     ]
    }
   ],
   "source": [
    "vocab = {}  # maps word to integer representing it\n",
    "word_encoding = 1\n",
    "def bag_of_words(text):\n",
    "    global word_encoding\n",
    "\n",
    "    words = text.lower().split(\" \")  # create a list of all of the words in the text, well assume there is no grammar in our text for this example\n",
    "    bag = {}  # stores all of the encodings and their frequency\n",
    "\n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            encoding = vocab[word]  # get encoding from vocab\n",
    "        else:\n",
    "            vocab[word] = word_encoding\n",
    "            encoding = word_encoding\n",
    "            word_encoding += 1\n",
    "    \n",
    "        if encoding in bag:\n",
    "            bag[encoding] += 1\n",
    "        else:\n",
    "            bag[encoding] = 1\n",
    "  \n",
    "    return bag\n",
    "\n",
    "text = \"this is a test to see if this test will work is is test a a\"\n",
    "bag = bag_of_words(text)\n",
    "print(bag)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d87988ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1}\n",
      "Negative: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 21: 1, 18: 1, 19: 1, 20: 1, 17: 1}\n"
     ]
    }
   ],
   "source": [
    "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\n",
    "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\n",
    "\n",
    "pos_bag = bag_of_words(positive_review)\n",
    "neg_bag = bag_of_words(negative_review)\n",
    "\n",
    "print(\"Positive:\", pos_bag)\n",
    "print(\"Negative:\", neg_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d57c812",
   "metadata": {},
   "source": [
    "### Integer Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f92bce2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 1, 4, 8, 9, 2, 2, 4, 3, 3]\n",
      "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
     ]
    }
   ],
   "source": [
    "vocab = {}  \n",
    "word_encoding = 1\n",
    "def one_hot_encoding(text):\n",
    "    global word_encoding\n",
    "\n",
    "    words = text.lower().split(\" \") \n",
    "    encoding = []  \n",
    "\n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            code = vocab[word]  \n",
    "            encoding.append(code) \n",
    "        else:\n",
    "            vocab[word] = word_encoding\n",
    "            encoding.append(word_encoding)\n",
    "            word_encoding += 1\n",
    "  \n",
    "    return encoding\n",
    "\n",
    "text = \"this is a test to see if this test will work is is test a a\"\n",
    "encoding = one_hot_encoding(text)\n",
    "print(encoding)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c16f50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: [10, 11, 12, 13, 14, 15, 5, 16, 17, 18, 19, 14, 20, 21]\n",
      "Negative: [10, 11, 12, 13, 14, 15, 5, 16, 21, 18, 19, 14, 20, 17]\n"
     ]
    }
   ],
   "source": [
    "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\n",
    "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\n",
    "\n",
    "pos_encode = one_hot_encoding(positive_review)\n",
    "neg_encode = one_hot_encoding(negative_review)\n",
    "\n",
    "print(\"Positive:\", pos_encode)\n",
    "print(\"Negative:\", neg_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0422a5f",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "\n",
    "It attempts to not only encode the frequency and order of words but the meaning of those words in the sentence. It encodes each word as a dense vector that represents its context in the sentence.\n",
    "\n",
    "Unlike the previous techniques word embeddings are learned by looking at many different training examples. You can add what's called an embedding layer to the beggining of your model and while your model trains your embedding layer will learn the correct embeddings for words. You can also use pretrained embedding layers.\n",
    "\n",
    "This is the technique we will use for our examples and its implementation will be showed later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a0127",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcae0e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "VOCAB_SIZE = 88584\n",
    "\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66777c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 194,\n",
       " 1153,\n",
       " 194,\n",
       " 8255,\n",
       " 78,\n",
       " 228,\n",
       " 5,\n",
       " 6,\n",
       " 1463,\n",
       " 4369,\n",
       " 5012,\n",
       " 134,\n",
       " 26,\n",
       " 4,\n",
       " 715,\n",
       " 8,\n",
       " 118,\n",
       " 1634,\n",
       " 14,\n",
       " 394,\n",
       " 20,\n",
       " 13,\n",
       " 119,\n",
       " 954,\n",
       " 189,\n",
       " 102,\n",
       " 5,\n",
       " 207,\n",
       " 110,\n",
       " 3103,\n",
       " 21,\n",
       " 14,\n",
       " 69,\n",
       " 188,\n",
       " 8,\n",
       " 30,\n",
       " 23,\n",
       " 7,\n",
       " 4,\n",
       " 249,\n",
       " 126,\n",
       " 93,\n",
       " 4,\n",
       " 114,\n",
       " 9,\n",
       " 2300,\n",
       " 1523,\n",
       " 5,\n",
       " 647,\n",
       " 4,\n",
       " 116,\n",
       " 9,\n",
       " 35,\n",
       " 8163,\n",
       " 4,\n",
       " 229,\n",
       " 9,\n",
       " 340,\n",
       " 1322,\n",
       " 4,\n",
       " 118,\n",
       " 9,\n",
       " 4,\n",
       " 130,\n",
       " 4901,\n",
       " 19,\n",
       " 4,\n",
       " 1002,\n",
       " 5,\n",
       " 89,\n",
       " 29,\n",
       " 952,\n",
       " 46,\n",
       " 37,\n",
       " 4,\n",
       " 455,\n",
       " 9,\n",
       " 45,\n",
       " 43,\n",
       " 38,\n",
       " 1543,\n",
       " 1905,\n",
       " 398,\n",
       " 4,\n",
       " 1649,\n",
       " 26,\n",
       " 6853,\n",
       " 5,\n",
       " 163,\n",
       " 11,\n",
       " 3215,\n",
       " 10156,\n",
       " 4,\n",
       " 1153,\n",
       " 9,\n",
       " 194,\n",
       " 775,\n",
       " 7,\n",
       " 8255,\n",
       " 11596,\n",
       " 349,\n",
       " 2637,\n",
       " 148,\n",
       " 605,\n",
       " 15358,\n",
       " 8003,\n",
       " 15,\n",
       " 123,\n",
       " 125,\n",
       " 68,\n",
       " 23141,\n",
       " 6853,\n",
       " 15,\n",
       " 349,\n",
       " 165,\n",
       " 4362,\n",
       " 98,\n",
       " 5,\n",
       " 4,\n",
       " 228,\n",
       " 9,\n",
       " 43,\n",
       " 36893,\n",
       " 1157,\n",
       " 15,\n",
       " 299,\n",
       " 120,\n",
       " 5,\n",
       " 120,\n",
       " 174,\n",
       " 11,\n",
       " 220,\n",
       " 175,\n",
       " 136,\n",
       " 50,\n",
       " 9,\n",
       " 4373,\n",
       " 228,\n",
       " 8255,\n",
       " 5,\n",
       " 25249,\n",
       " 656,\n",
       " 245,\n",
       " 2350,\n",
       " 5,\n",
       " 4,\n",
       " 9837,\n",
       " 131,\n",
       " 152,\n",
       " 491,\n",
       " 18,\n",
       " 46151,\n",
       " 32,\n",
       " 7464,\n",
       " 1212,\n",
       " 14,\n",
       " 9,\n",
       " 6,\n",
       " 371,\n",
       " 78,\n",
       " 22,\n",
       " 625,\n",
       " 64,\n",
       " 1382,\n",
       " 9,\n",
       " 8,\n",
       " 168,\n",
       " 145,\n",
       " 23,\n",
       " 4,\n",
       " 1690,\n",
       " 15,\n",
       " 16,\n",
       " 4,\n",
       " 1355,\n",
       " 5,\n",
       " 28,\n",
       " 6,\n",
       " 52,\n",
       " 154,\n",
       " 462,\n",
       " 33,\n",
       " 89,\n",
       " 78,\n",
       " 285,\n",
       " 16,\n",
       " 145,\n",
       " 95]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aebd9e5",
   "metadata": {},
   "source": [
    "making each review the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "137abe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
    "test_data = sequence.pad_sequences(test_data, MAXLEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0292bd",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee9edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c45f7c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          2834688   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,843,041\n",
      "Trainable params: 2,843,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4da59903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 28s 42ms/step - loss: 0.4162 - acc: 0.8134 - val_loss: 0.2907 - val_acc: 0.8830\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.2392 - acc: 0.9076 - val_loss: 0.3908 - val_acc: 0.8524\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1859 - acc: 0.9304 - val_loss: 0.2684 - val_acc: 0.8874\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 23s 38ms/step - loss: 0.1507 - acc: 0.9460 - val_loss: 0.2925 - val_acc: 0.8858\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 27s 44ms/step - loss: 0.1281 - acc: 0.9545 - val_loss: 0.3223 - val_acc: 0.8838\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.1113 - acc: 0.9615 - val_loss: 0.3199 - val_acc: 0.8900\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0974 - acc: 0.9666 - val_loss: 0.3856 - val_acc: 0.8854\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0856 - acc: 0.9715 - val_loss: 0.3673 - val_acc: 0.8844\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 31s 49ms/step - loss: 0.0764 - acc: 0.9742 - val_loss: 0.3779 - val_acc: 0.8906\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0684 - acc: 0.9784 - val_loss: 0.4615 - val_acc: 0.8676\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f41c761e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 11ms/step - loss: 0.6223 - acc: 0.8222\n",
      "[0.6222668886184692, 0.8222000002861023]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68650bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def encode_text(text):\n",
    "    tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
    "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "    return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
    "\n",
    "text = \"that movie was just amazing, so amazing\"\n",
    "encoded = encode_text(text)\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d89896d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that movie was just amazing so amazing\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "\n",
    "def decode_integers(integers):\n",
    "    PAD = 0\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "        if num != PAD:\n",
    "            text += reverse_word_index[num] + \" \"\n",
    "\n",
    "    return text[:-1]\n",
    "  \n",
    "print(decode_integers(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1a48fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85748625]\n",
      "[0.38191178]\n"
     ]
    }
   ],
   "source": [
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1,250))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred) \n",
    "    print(result[0])\n",
    "\n",
    "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
    "predict(positive_review)\n",
    "\n",
    "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
    "predict(negative_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766ce318",
   "metadata": {},
   "source": [
    "## RNN Play Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60cae4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9028875",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "741f0157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a53f57ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d40a3",
   "metadata": {},
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c3dfb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text):\n",
    "    return np.array([char2idx[c] for c in text])\n",
    "\n",
    "text_as_int = text_to_int(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d44afeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: First Citizen\n",
      "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "print(\"Text:\", text[:13])\n",
    "print(\"Encoded:\", text_to_int(text[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6c88edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen\n"
     ]
    }
   ],
   "source": [
    "def int_to_text(ints):\n",
    "    try:\n",
    "        ints = ints.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    return ''.join(idx2char[ints])\n",
    "\n",
    "print(int_to_text(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583aaac",
   "metadata": {},
   "source": [
    "creating training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ef0b214",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100  # length of sequence for a training example\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30aec1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33e2f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):  # for the example: hello\n",
    "    input_text = chunk[:-1]  # hell\n",
    "    target_text = chunk[1:]  # ello\n",
    "    return input_text, target_text  # hell, ello\n",
    "\n",
    "dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f974a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "\n",
      "OUTPUT\n",
      "irst Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You \n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you \n",
      "\n",
      "OUTPUT\n",
      "re all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you k\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(2):\n",
    "    print(\"\\n\\nEXAMPLE\\n\")\n",
    "    print(\"INPUT\")\n",
    "    print(int_to_text(x))\n",
    "    print(\"\\nOUTPUT\")\n",
    "    print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f894a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6980b4d1",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c27609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (64, None, 256)           16640     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,330,241\n",
      "Trainable params: 5,330,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "      ])\n",
    "    return model\n",
    "\n",
    "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149f25d9",
   "metadata": {},
   "source": [
    "loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93839093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ef97484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[ 3.9832797e-03 -4.3352507e-04 -5.4502045e-04 ... -1.7849426e-04\n",
      "   -6.6202017e-04 -3.9503782e-04]\n",
      "  [ 5.8844378e-03 -5.7231011e-03 -1.6380940e-03 ...  1.2608948e-03\n",
      "   -2.6878808e-03  4.5561413e-03]\n",
      "  [ 2.5902861e-03  2.7363282e-04  2.7462770e-03 ...  3.2611808e-03\n",
      "    2.2406138e-03  8.5719936e-03]\n",
      "  ...\n",
      "  [ 8.5322000e-03 -7.5981109e-03 -5.2043539e-04 ... -1.3035480e-03\n",
      "    6.5418966e-03 -3.1635284e-03]\n",
      "  [ 2.7310944e-03 -7.7114888e-03 -3.3030305e-03 ... -4.6551162e-03\n",
      "    1.0336631e-02 -7.3442853e-04]\n",
      "  [ 3.4876596e-03 -8.1091970e-03 -1.5885985e-03 ... -9.3047759e-03\n",
      "    1.0606967e-02  3.3018803e-03]]\n",
      "\n",
      " [[-1.2054029e-03 -4.1164425e-03 -5.5347858e-03 ...  4.2412402e-03\n",
      "    4.6510645e-03  6.8038161e-04]\n",
      "  [-2.2224812e-03 -3.8065878e-03  1.1026461e-03 ...  5.7890778e-03\n",
      "    5.7398221e-03  3.5987548e-03]\n",
      "  [ 2.4411255e-03 -2.7729294e-03 -3.8660830e-05 ...  4.1681272e-03\n",
      "    3.8985997e-03  1.6239621e-03]\n",
      "  ...\n",
      "  [ 4.9463706e-05 -4.8336666e-03 -4.2293807e-03 ...  2.5806227e-03\n",
      "    4.6508880e-03 -3.0085882e-03]\n",
      "  [ 4.6602269e-03 -3.5486105e-03 -4.5217699e-03 ...  2.2572142e-03\n",
      "    2.6947362e-03 -1.2961624e-03]\n",
      "  [ 4.8669716e-03 -5.0998512e-03 -3.0086837e-03 ... -2.0553120e-03\n",
      "    3.7964953e-03  2.5579305e-03]]\n",
      "\n",
      " [[-9.1944460e-04 -4.0453058e-03 -4.6263757e-04 ... -1.2007641e-03\n",
      "    4.8956024e-03  1.0847088e-03]\n",
      "  [-2.5271848e-03  2.3906247e-03  2.3929132e-03 ...  1.0809198e-03\n",
      "    8.5170334e-03  5.4770443e-03]\n",
      "  [-9.8170759e-04 -1.8851289e-03  1.8759662e-03 ... -4.0170075e-03\n",
      "    9.2046158e-03  5.3240731e-03]\n",
      "  ...\n",
      "  [-1.9462081e-03  8.1803780e-03 -6.1649294e-04 ... -7.2755520e-03\n",
      "    1.2505641e-03 -2.7406921e-03]\n",
      "  [-3.5561486e-03  1.1366181e-02  3.7220509e-03 ... -3.7954149e-03\n",
      "    6.2986864e-03  4.0236954e-03]\n",
      "  [ 2.0940858e-03  8.7484336e-03  5.1009003e-03 ...  1.9119228e-03\n",
      "    8.4751500e-03  2.4667538e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-9.1944460e-04 -4.0453058e-03 -4.6263757e-04 ... -1.2007641e-03\n",
      "    4.8956024e-03  1.0847088e-03]\n",
      "  [-6.2338234e-04 -2.7095000e-03  1.4480262e-04 ... -1.7866514e-03\n",
      "    9.6832318e-03  4.9472041e-03]\n",
      "  [-1.4777596e-03 -5.8058877e-03 -1.1575667e-03 ... -2.1446301e-03\n",
      "    1.3263750e-02  5.1956093e-03]\n",
      "  ...\n",
      "  [ 2.8949520e-03 -1.6679161e-03 -2.1840383e-03 ...  1.5088519e-03\n",
      "    8.6511541e-03  1.0955449e-02]\n",
      "  [ 7.9645878e-03 -1.5545583e-03 -2.2375393e-03 ...  1.2787308e-03\n",
      "    7.1082916e-03  7.9169292e-03]\n",
      "  [ 1.1837096e-03 -5.8318349e-04 -2.2735624e-03 ... -3.0605898e-03\n",
      "    5.7973610e-03  6.3674720e-03]]\n",
      "\n",
      " [[ 4.9431052e-04  3.5981638e-03 -5.9597134e-03 ...  6.3285558e-04\n",
      "    1.5781544e-03 -2.3228407e-03]\n",
      "  [ 1.0467350e-03  8.5986843e-03 -7.9344464e-03 ... -2.1954835e-03\n",
      "   -7.7445293e-07 -7.9593407e-03]\n",
      "  [ 1.6065576e-03  4.6500503e-03 -5.3509800e-03 ... -6.4991708e-03\n",
      "    1.5065428e-03 -3.3123745e-03]\n",
      "  ...\n",
      "  [ 2.4238976e-03 -4.0087895e-03 -7.1923365e-03 ... -6.7054057e-03\n",
      "    3.3056298e-03  5.8725486e-03]\n",
      "  [-1.8583268e-03 -4.5114076e-03 -8.5342526e-03 ... -8.6377300e-03\n",
      "    6.9099367e-03  5.8242916e-03]\n",
      "  [-2.6843227e-03  2.2564251e-03 -2.3245194e-03 ... -5.2012913e-03\n",
      "    9.9346451e-03  1.1102936e-02]]\n",
      "\n",
      " [[ 2.6101861e-03  5.1917443e-03 -2.1800108e-03 ...  2.3611188e-03\n",
      "    1.1730788e-03  3.8152782e-03]\n",
      "  [ 5.7750940e-03  3.5751057e-03 -1.7299878e-03 ...  1.2353545e-03\n",
      "    9.3218405e-05  2.5489922e-03]\n",
      "  [ 5.8274274e-03 -2.9626535e-03  2.6237706e-03 ... -1.7616116e-03\n",
      "    1.8051348e-03  5.2999123e-05]\n",
      "  ...\n",
      "  [ 7.1977205e-03 -3.8767115e-03  1.5875748e-03 ... -2.2199766e-03\n",
      "    8.5786274e-03 -3.1952425e-03]\n",
      "  [ 8.9138811e-03  1.5687849e-03  3.9322767e-05 ... -8.2669884e-04\n",
      "    8.1541566e-03  2.5065788e-03]\n",
      "  [ 1.1160431e-02  5.2576605e-04  6.9930125e-04 ... -2.3409249e-03\n",
      "    5.6415689e-03  2.3658732e-03]]], shape=(64, 100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(len(example_batch_predictions))\n",
    "print(example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "148d0246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[ 0.00398328 -0.00043353 -0.00054502 ... -0.00017849 -0.00066202\n",
      "  -0.00039504]\n",
      " [ 0.00588444 -0.0057231  -0.00163809 ...  0.00126089 -0.00268788\n",
      "   0.00455614]\n",
      " [ 0.00259029  0.00027363  0.00274628 ...  0.00326118  0.00224061\n",
      "   0.00857199]\n",
      " ...\n",
      " [ 0.0085322  -0.00759811 -0.00052044 ... -0.00130355  0.0065419\n",
      "  -0.00316353]\n",
      " [ 0.00273109 -0.00771149 -0.00330303 ... -0.00465512  0.01033663\n",
      "  -0.00073443]\n",
      " [ 0.00348766 -0.0081092  -0.0015886  ... -0.00930478  0.01060697\n",
      "   0.00330188]], shape=(100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9f42c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "tf.Tensor(\n",
      "[ 3.9832797e-03 -4.3352507e-04 -5.4502045e-04 -3.6653306e-03\n",
      "  3.8743597e-03 -1.3538413e-03 -8.0508937e-04  4.0859493e-05\n",
      "  3.0082874e-03  1.9266575e-03  1.2154251e-02  5.5690240e-03\n",
      "  3.4563898e-03 -7.5126952e-03 -5.5070780e-04 -2.4169432e-03\n",
      "  3.5892772e-03  4.5903479e-03 -3.2490315e-03  1.1045387e-03\n",
      "  2.1733386e-03  2.3194165e-03  1.7768067e-03 -4.2773336e-03\n",
      " -1.1283718e-04  5.4641762e-03 -5.0865929e-04  1.1294456e-03\n",
      "  1.3249204e-04 -4.3496280e-03  8.4950868e-03  1.1413742e-03\n",
      "  2.5721896e-03  2.3108658e-03 -6.7476742e-03 -1.4392820e-03\n",
      "  1.0719163e-03  1.9055088e-03  4.0898609e-04  3.7891758e-03\n",
      "  2.4635508e-04  1.2034554e-03 -2.3581746e-03  9.2050582e-03\n",
      "  2.9189507e-03 -5.1036733e-03 -1.0822295e-03  6.8863910e-03\n",
      "  1.1189389e-03 -1.2560295e-03 -4.7998637e-04 -4.6655945e-03\n",
      " -5.1624561e-04 -1.4578549e-03  2.5017196e-03  1.3079562e-03\n",
      "  2.4401392e-03 -3.7029702e-03  1.9507530e-03  1.1097884e-03\n",
      " -1.1984726e-03  1.3170172e-03 -1.7849426e-04 -6.6202017e-04\n",
      " -3.9503782e-04], shape=(65,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "586f67f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"jO!3eKNF$rjXhl?\\n' sicH&zBp;NjHNDE$nIDejLhzKAjtxJCcWvf3MfZKuCRrpFdyx;v,qxYr\\nhQgfWqHwBkm;gIyEh-$sgXCe!\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
    "\n",
    "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
    "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
    "predicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d85912c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b45199c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae145c2",
   "metadata": {},
   "source": [
    "checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3edc00e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73416ef1",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2aec4fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "172/172 [==============================] - 312s 2s/step - loss: 2.5788\n",
      "Epoch 2/3\n",
      "172/172 [==============================] - 321s 2s/step - loss: 1.8796\n",
      "Epoch 3/3\n",
      "172/172 [==============================] - 331s 2s/step - loss: 1.6315\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, epochs=3, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30765f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "236ebc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8612b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_num = 2\n",
    "# model.load_weights(tf.train.load_checkpoint(\"./training_checkpoints/ckpt_\" + str(checkpoint_num)))\n",
    "# model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f5aef",
   "metadata": {},
   "source": [
    "generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "057243c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 800\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "    \n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53f83a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type a starting string: hello\n",
      "hellow it,\n",
      "To be this envise the droud espict your grown takely own grace Is. I have laye as chaiter-tay's with mank:\n",
      "So sweat me.\n",
      "\n",
      "JULIET:\n",
      "Now speak, have husberghands a woman,\n",
      "Your lords Dord or thy brothern, fresh too counded by thee.\n",
      "\n",
      "ABUSLY:\n",
      "Sir, lowingst of the news, Nore and lives well spike.\n",
      "\n",
      "JULIET:\n",
      "A parcous simely word justless, hand I prighty.\n",
      "\n",
      "AUHION\n",
      "ENWER: did she sarmy far, ent you you fairt him\n",
      "Ammanaligita and he parous.\n",
      "\n",
      "JUDIET:\n",
      "No make your'ers, Henry noves is mean unillon\n",
      "Con the Vapricar's party, is counce,\n",
      "I will marry place\n",
      "Tull a looke furth with a hearper,\n",
      "I'll counte a begt in the duken hath somes spill\n",
      "That lad bace assiane that ame\n",
      "Then deed sour fair, me: like apay; bust you\n",
      "Proan the children of him and call as herewas;\n",
      "Say, burds; receavesh me: undist: but come, t\n"
     ]
    }
   ],
   "source": [
    "inp = input(\"Type a starting string: \")\n",
    "print(generate_text(model, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed6d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
